---
title: "Transforming and analyzing data"
description: "Learn and implement data wrangling verbs"
author: "Andrew Ba Tran"
date: 2018-05-27T21:13:14-05:00
categories: ["R"]
tags: ["R", "wrangling", "dplyr"]
weight: 1
slug: dplyr
disableTOC: "false"
---


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/LhPSyL9CK7w?t=3s" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0; encrypted-media" allowfullscreen title="YouTube Video"></iframe>
</div>


Why use **dplyr**?

* Designed to work with data frames, which is what journalists are used to
* Great for data exploration and transformation
* Intuitive to write and easy to read, especially when using the "chaining" syntax of pipes

## Five basic verbs

* `filter()`
* `select()`
* `arrange()`
* `mutate()`
* `summarize()` plus `group_by()`


## Our data

We're going to be wrangling some pretty big data-- murders over decades across the country. 

This case-level data was acquired by the [Murder Accountability Project](http://www.murderdata.org/p/data-docs.html) from the Justice Department. 

We're going to use the basics of **dplyr** verb functions to analyze the data and see if there are any stories there might be worth pursuing. 

Remember that huge SPSS data set we imported in the previous chapter?

I saved all that code we wrote to import it, renaming columns, and joining values and labels into an R script: *import_murders.R*. This is reproducibility in action.

Check out [what it looks like](https://github.com/r-journalism/learn-chapter-3/blob/master/dplyr/import_murders.R)-- it's about 100 lines of code long but only one line is required to run the script below.

{{% notice warning %}}
Before running the command, make sure the script is in the working directory folder (which should be the *case_study* subfolder of the (*learn-chapter-3-master* folder) and that the **SHR76_16.sav.zip** file is in the *data* sub folder. 
{{% /notice %}}

**This is going to take a few minutes to run.** 

```{r importing_data, warning=F, message=F}
source("import_murders.R")
```

Alright, the **import_murders.R** script unzipped data, imported it, and transformed it into a workable dataframe and saved it to our environment as the object **murders** for us to analyze. You probably got some warnings in the console but that's okay.

```
View(murders)
```

![](/wrangling/dplyr/images/murders.png?classes=shadow)


Here's the [data dictionary](https://www.dropbox.com/s/lo6tgo8nnbpqeru/MAPdefinitionsSHR.pdf?dl=1).

What are we dealing with here?

## Number of rows (cases)?

```{r rows}
nrow(murders)
```

## How many municipalities?

We'll use a couple base R functions: `unique()` and `length()`.

```{r cities}
# Make a list of cities based on the unique() function
how_many <- unique(murders$MSA_label)

# Count up how many are in the list
length(how_many)
```

Whew, let's not overwhelm ourselves with all this data as we're getting started out.

When I get a new data set I like to see what it's made of. So I can begin to get a sense of how to summarize it or take it apart.

Start with the `glimpse()` function from **dplyr**-- it will give a brief look at the variables in the data set and the data type. 

```{r glimpse}
glimpse(murders)
```

Then, I'll go through the variables that interest me to see how many types there are. The more variables (columns) you have in a data set that are categorical, the deeper you can dive in analyzing it.

For example, if you had a data set with a list of salaries (1 variable) you could:

* Figure out the median salary
* Calculate the difference between the highest and the lowest salaries

If you had a data set with salaries and gender of worker (2 variables) you could additionally:

* Figure out median salary for men and women
* Calculate the differences in those medians

If you had a data set with salaries and gender of worker and state where they live  (3 variables) you could additionally:

* Find out median salary per state
* Figure out median salary for men and women per state
* Determine which state had the biggest disparity
* See which state women get paid more than men

This is what we'll do with this particular data set:

Let's narrow down our scope by using the `filter()` function.

![](/wrangling/dplyr/images/filter.png)

Filter works by extracting rows that meet a criteria you set.

![](/wrangling/dplyr/images/filter_specifics.png)

You pass the dataframe as a variable to `filter()` first and then you add any logical tests.


{{% notice warning %}}
One `=` in R is the same as `<-` in that it assigns a value. Logical tests requires two, so  `==` which tests for equal.
{{% /notice %}}

```{r filter2}
df1 <- filter(murders, Relationship_label=="Husband", VicAge > 60, Year==2016)

df2 <- filter(murders, Relationship_label=="Husband" & VicAge > 60 & Year==2016) # same as the line above

df3 <- filter(murders, Relationship_label %in% c("Husband", "Boyfriend") | Circumstance_label=="Lovers triangle")
```

Check out the new objects in the Environment window of RStudio.

![](/wrangling/dplyr/images/3dfs.png?classes=shadow?width=20pc)

Data frames df1 and df2 are exactly the same (Looking for cases in which Husbands were involved, the victim was older than 60, and occurred in 2016)-- only 25 were found. Meanwhile d3 has nearly 32,000 cases in which a Husband or Boyfriend were involved or it was labeled by investigators as a lover's triangle.

## Logical Operators

| Operator | Description |
| ------ | ------------------------ |
| `<` | Less than |
| `<=` | Less than or equal to |
| `>`    | Greater than |
| `>=`    | Greater than or equal to |
| `==`    | Exactly equal to |
| `!=`    | Not equal to |
| `!x`    | Not x |
| `x | y`    | x or y |
| `x & y`    | x and y |
| `%in%`    | Group membership
| `isTRUE(x)`    | Test if x is TRUE |
| `is.na(x)`    | Test if x is NA |
| `!is.na(x)`    | Test if x is not NA |

**Test yourself**

Can you use the logical operators and `filter()` to create **df4** which has all the data for murders: 

1. in the District of Columbia
2. that were solved in 2015
3. that involved Black victims
4. in which "Handgun - pistol, revolver, etc" was weapon used
5. in which the victim was between the ages of 18 and 21

----

**Common mistakes**

1. Using `=` instead of `==`

```
# WRONG
filter(murders, fstate_label="District of Columbia")

# RIGHT
filter(murders, fstate_label=="District of Columbia")
```

2. Forgetting quotes

```
# WRONG
filter(murders, fstate_label=District of Columbia)

# RIGHT
filter(murders, fstate_label="District of Columbia")
```

3. Collapsing multiple tests into one

```
# WRONG
filter(murders, 1980 < year < 1990)

# RIGHT
filter(murders, 1980 < year, year < 1990)
```

4. Stringing together many tests instead of using %in%

```
# Not WRONG but INEFFICIENT to type out
filter(murders, VicRace_label=="Black" | VicRace_label="Unknown" | VicRace_label=="Asian or Pacific Islander")

# RIGHT
filter(murders, VicRace_label %in% c("Black", "Unknown", "Asian or Pacific Islander"))
```


Alright, we've got new data frames narrowed down from 750,000 total to about 25 specific incidents of husbands murdering their partners who were older than 60 in 2016 and about 32,000 cases where either the husband or boyfriend was involved or the victim was involved in a love triangle.

We have 47 variables (aka columns) and we don't need all of them for this basic analysis. Let's narrow that down.

------

## select()

![](/wrangling/dplyr/images/select.png?classes=shadow)

You simply list the column names after the data frame you want to extract from.

```{r select1}
df1_narrow <- select(df1, State, Agency, Solved_label, Year)
```

```
View(df1_narrow)
```

![](/wrangling/dplyr/images/df1.png?classes=shadow)

You can use a colon between column names if you want all the columns between.

```{r select2}
df2_narrow <- select(df1, State, OffAge:OffRace_value, Weapon_label)
```


```
View(df2_narrow)
```
![](/wrangling/dplyr/images/df2.png?classes=shadow)


Use a `-` next to a column name to drop it (You can drop more than one column at a time, too).
```{r select3}
# modifying the data frame created above
df3_narrow <- select(df2_narrow, -Weapon_label)
```

```
View(df3_narrow)
```

![](/wrangling/dplyr/images/df3.png?classes=shadow)

There are so many other functions you can use with `select()` to help make your life easier.

```
# This extracts all variables with names that contain "_label"

labels_only_columns <- select(murders, contains("_label"))
str(labels_only_columns)
```

Check out all the neat `select()` options [here](https://dplyr.tidyverse.org/reference/select_helpers.html).

Great, let's move on to the next verb.

-----

## arrange()

![](/wrangling/dplyr/images/arrange.png)

You can include more than one variable (column)-- the first one will take priority but subsequent variables will serve as tie breakers.

![](/wrangling/dplyr/images/arrange_syntax.png)


```{r arrange}
age_df1 <- arrange(murders, VicAge)

age_df2 <- arrange(murders, VicAge, OffAge)

age_df3 <- arrange(murders, VicAge, desc(OffAge))

# Same result as above
age_df3b <- arrange(murders, VicAge, -OffAge)
```

This will be very useful. Let's move on to the next verb.

------


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/awZQR_j7CTI?t=3s" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0; encrypted-media" allowfullscreen title="YouTube Video"></iframe>
</div>



## mutate()

![](/wrangling/dplyr/images/mutate.png)

We can create new variables (new columns) with the `mutate()` function.

![](/wrangling/dplyr/images/mutate_syntax.png)


```{r mutate1}
murders_ver2 <- mutate(murders,
                       age_difference=OffAge-VicAge)
```

```
View(murders_ver2)
```

![](/wrangling/dplyr/images/mutate1.png?classes=shadow)

## Arithmetic Operators

| Operator | Description |
| ------ | ------------------------ |
| `+` | Addition |
| `-` | Subtraction |
| `*`    | Multiplication |
| `/`    | Division |
| `^`    | Exponentiation |

You can do more than just math in the context of `mutate()`.

You can use `case_when()` in `mutate()` to create new values based on other values, kind of like an if_else statement.

```{r mutate2}
# creates an age_difference column
# and creates a vic_category column that is populated with values depending on the VicRace_label column

murders_ver3 <- mutate(murders,
                       age_difference=OffAge-VicAge,
                       vic_category=case_when(
                         VicRace_label == "White" ~ "White",
                         VicRace_label != "White" ~ "Non-White"
                       ))
```


{{% notice tip %}}
This is the first of a few times you'll see the `~` (tilde) operator. It means it's a one-sided formula, usually in statistical model formulas. It can be described as "[depends on](https://stackoverflow.com/questions/14976331/use-of-tilde-in-r-programming-language)" You don't need to really to understand why a tilde is necessary-- only that this is how this particular function needs to be set up to work successfully. 
{{% /notice %}}




There are two variables being created in the `mutate()` function separated by commas. 

* one is **age_difference** which just subtracts the values in **OffAge** and **VicAge**.
* the other is **vic_category** that is either assigned "White" or "Non-White" depending on if the value of the column **VicRace_label** is "White" or *not* "White".

```
View(murders_ver3)
```


![](/wrangling/dplyr/images/white.png?classes=shadow)

This is an example of a vectorized function in action. There are some really great ones like `lag()` and `lead()` and `rank()` and we might get into them later. In the meantime, here's a [neat list](https://dplyr.tidyverse.org/reference/mutate.html#useful-functions).

## Rename

You can rename variables (columns) easily with the function `rename()`

```{r rename}
colnames(df3_narrow)

# OK, you see the column names above-- let's change a couple of them

df3_renamed <- rename(df3_narrow, 
                      offender_gender=OffSex_label,
                      offender_age=OffAge)
colnames(df3_renamed)
```

You can also rename variables (columns) with the `select()` function. This is just a way to cut down on extra lines of code

```{r select_rename}
colnames(df3_narrow)

# Keeping only the State and offender gender and age columns but renaming the OffSex_label and OffAge columns

df4_renamed <- select(df3_narrow,
                      State,
                      offender_gender=OffSex_label,
                      offender_age=OffAge)

df4_renamed
```

-----

## summarize()

![](/wrangling/dplyr/images/summarize.png)

This is the equivalent of creating a pivot table in Excel.

You're aggregating the whole table into something simplified.

```{r summarize1}
summarize(murders, average_victim_age=mean(VicAge))
```

You can create a table of summaries.


```{r summarize2}
summarize(murders, 
          average_victim_age=mean(VicAge), 
          average_offender_age=mean(OffAge))
```


{{% notice warning %}}
There's something wrong with the average_offender_age value. Can you figure out what happened?
{{% /notice %}}

Summarize the data frame **murders**

```{r summarize4}
summarize(murders, 
          first=min(Year), 
          last=max(Year),
          metro_areas=n_distinct(MSA_label),
          cases=n())
```

-----

## group_by()

You can aggregate data by groups before summarizing.

![](/wrangling/dplyr/images/groupby.png)

```{r summarize3}
# This is the same process as before but we're telling R to group up the metro areas before summarizing the data

murders <- group_by(murders, MSA_label)

summarize(murders, 
          first=min(Year), 
          last=max(Year),
          cases=n())
```

This might be a tough concept to fully understand at first, but we'll go over a few more examples soon so it will hopefully make more sense.

Also, I want to point out that the opposite of `group_by()` is `ungroup()` which you might need later on as you progress.

But let's get over some very useful functionality that comes with the **dplyr** package.

-----



<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/cOaXB4JfyXw?t=3s" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0; encrypted-media" allowfullscreen title="YouTube Video"></iframe>
</div>

## pipe %>%

Data analyses will most often involve more than one step.

We're going to over some **options** on how to approach multi-step processes with this data set and then we'll go over the *best* way to deal with them.

Description of theoretical process to run on the **murders** data frame:

1. **Extract rows** for cases that happened in Washington DC, then
2. **Group** case by year and then
3. **Count** the number of cases
4. **Arrange** the by decreasing cases

**Option 1**

Build out a new dataframe for each step.

```{r multi1}
dc_annual_murders1 <- filter(murders, State=="District of Columbia")
dc_annual_murders2 <- group_by(dc_annual_murders1, Year)
dc_annual_murders3 <- summarize(dc_annual_murders2, total=n())
dc_annual_murders4 <- arrange(dc_annual_murders3, desc(total))

# looking at the first 6 rows of data

head(dc_annual_murders4)
```

**Option 2**

Do it all in one line by nesting functions.

```{r multi2}
dc_annual_murders <- arrange(summarize(group_by(filter(murders, State=="District of Columbia"), Year), total=n()), desc(total))

# looking at the first 6 rows of data

head(dc_annual_murders)
```

These options aren't great because the first one involves just way too much typing, even if it's pretty clear to an outside reader what's happening to the data frame. The second one is no good because, while it's efficient with coding, it's way too difficult to follow what's happening to the data.

Let's talk about the pipe operator `%>%`

You might have noticed that all the functions from **dplyr** all structured similarly: *The first argument is always the data frame.*

It takes in a data frame and spits out a data frame.

This function structure is what allows for something like the `%>%` to work.

![](/wrangling/dplyr/images/pipe.png)

These commands do the same thing. Give it a try.

```{r pipes3}
filter(murders, OffAge==2)

murders %>% filter(OffAge==2)
```

In essence, a `%>%` is the grammatical equivalent of *and then...*.

Again, a description of the theoretical process:

* **Extract rows** for cases that happened in Washington DC, then
* **Group** case by year and then
* **Count** the number of cases
* **Arrange** the by decreasing cases

**Option 3**

Use the `%>%` pipe

```{r pipes4}
filter(murders, State=="District of Columbia") %>% 
  group_by(Year) %>% 
  summarize(total=n()) %>%    
  arrange(desc(total)) %>% 
  head()
```

So readable and simple, right?

Here's the shortcut to type `%>%` in RStudio:

* Mac: Cmd + Shift + M
* Windows: Ctrl + Shift + M

Why "M"? I think it's because the pipe was first introduced in the [**magrittr** package](https://cran.r-project.org/web/packages/magrittr/README.html) by Stefan Milton Bache.

## Mutate again

There are a lot of [interesting things](https://dplyr.tidyverse.org/reference/mutate.html#useful-functions) you can do with `mutate()`. 

Let's try out `lag()` within `mutate()` -- it lets you do math based on the previous row of a vector.

For example, in the data frame above we've got the number of murders in DC. With `lag()` and some math, we can calculate the difference in the number of murders year over year.

```{r pipes5}
# We can keep the code from before but now we add a new mutate line
filter(murders, State=="District of Columbia") %>% 
  group_by(Year) %>% 
  summarize(total=n()) %>%
  mutate(previous_year=lag(total)) %>% 
  mutate(change=total-previous_year)
```

So `mutate()` returns a vector the same length as the input.

We summarized the code and then we mutated a new column based on `lag()` and then we mutated a second column based on the new column and the old column.

You can use mutate more than once


```{r pipes6}
# Here's an example of the same code above but with mutate called just once
# previous_year was able to be referenced a second time because it was created in first
years <- filter(murders, State=="District of Columbia") %>% 
  group_by(Year) %>% 
  summarize(total=n()) %>%
  mutate(previous_year=lag(total), change=previous_year-total) 

years
```

So `mutate()` works when the formula you pass it returns a vectorized output. For example, if a vector has 10 instances in it, then the formula needs to output 10 instances, too.

Passing it a formula like `sum()` would confuse it.

```{r pipes7}
years %>% mutate(all_murders=sum(total))
```

This is what differentiates `mutate()` from `summarize()`.

## Summary functions

What `summarize()` does is it takes a vector as an input, and returns a single value as output. Like `sum()` did in the previous example.

Here are some examples of summary functions:


| Function | Description |
| ------ | ------------------------ |
| `mean(x)` | Mean (average). `mean(c(1,10,100,1000))` returns 277.75 |
| `median(x)` | Median. `median(c(1,10,100,1000))` returns 55 |
| `sd(x)`    | Standard deviation. `sd(c(1,10,100,1000))` returns 483.57 |
| `quantile(x, probs)`    | Where x is the numeric vector whose quantiles are desired and probs is a numeric vector with probabilities |
| `range(x)`    | Range. `range(c(1,10,100,1000))` returns c(1, 1000) and `diff(range(c(1,10,100,1000)))` returns 999|
| `sum(x)`    | Sum. `sum(c(1,10,100,1000))` returns 1111 |
| `min(x)`    | Minimum. `min(c(1,10,100,1000))` returns 1 |
| `max(x)`    | Maximum. `max(c(1,10,100,1000))` returns 1000 |
| `abs(x)`    | Absolute value. `abs(-8)` returns 8 |

Here are some examples of summary functions specific to **dplyr** and `summarize()` -- Learn about [the others](https://dplyr.tidyverse.org/reference/summarise.html#useful-functions).


| Function | Description |
| ------ | ------------------------ |
| `n()` | returns the number of values/rows |
| `n_distinct()` | returns number of uniques |
| `first()`    | Only returns the first value within an arranged group |
| `last()`    | Only returns the last value within an arranged group |
| `nth()`    | Only returns the nth location of a vector |

## group_by() again

Let's put together everything we've learned by calculating percentages.

You can use `group_by()` on more than one variable (column).

Let's go over the difference, really quick.

We can summarize the data by how many men were murdered versus women by

```{r group_by2a}
murders %>% 
  group_by(VicSex_label) %>% 
  summarize(total=n())
```

By grouping *VicSex_label* we got the counts (`n()`) for all the instances available in that variable.

We can add another variable (column) name into the `group_by()` to drill deeper. Watch what happens when we add *State*.

```{r group_by2b}
murders %>% 
  group_by(State, VicSex_label) %>% 
  summarize(total=n())
```

Interesting, right? The structure for the data here might be foreign to you. As it stands, this data is considered tidy. Each variable is a column and each observation (or case) is a row. This makes it easier to analyze the data in R and create charts.

But you're probably used to data that looks like

```{r group_by2c, echo=F}
library(tidyr)
murders %>% 
  group_by(State, VicSex_label) %>% 
  summarize(total=n()) %>% 
  spread(VicSex_label, total)
```

And that's fine, too, for presentation. We'll get into how to do this  later in the next chapter or so. 

The prior tidy structure makes it easier to run calculations such as percentages, however.

## Percents

Now we get a chance to chain together all the verbs we've used

```{r percents}
percent_murders <- murders %>% 
  group_by(State, VicSex_label) %>% 
  summarize(total=n()) %>% 
  # okay, we've got the total, now we can do some math with mutate
  mutate(percent=total/sum(total, na.rm=T)*100) 
  # did you notice the na.rm=T added to the sum function? This removes NAs
  # That's necessary because if you have a single NA then it will not sum correctly (thanks, statisticians!)

percent_murders
```

Interesting. We can use more `dplyr()` verbs to find something of interest. Like, which states have a higher percent of women murdered?

```{r percents2}
percent_murders_women <- murders %>% 
  group_by(State, VicSex_label) %>% 
  summarize(total=n()) %>% 
  mutate(percent=total/sum(total, na.rm=T)*100) %>% 
  filter(VicSex_label=="Female") %>% 
  arrange(-percent)

# Using the DT (DataTables) library that lets us create searchable tables with the plug-in for jQuery 
# If you don't have DT installed yet, uncomment the line below and run it
#install.packages("DT")

library(DT)
datatable(percent_murders_women)
```


Congratulations, we've gone through a bunch of ways to analyze data.

Now that we've got the tools, let's interrogate the data further using  a couple other methods involving tidying and joining data.

----

## Your turn

Challenge yourself with [these exercises](http://code.r-journalism.com/chapter-3/#section-transforming-and-analyzing-data) so you'll retain the knowledge of this section.

Instructions on how to run the exercise app are on the [intro page](https://learn.r-journalism.com/en/wrangling/) to this section.


-----

<span style="color:gray">© Copyright 2018, Andrew Ba Tran</span>



